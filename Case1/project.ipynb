{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creator(models_names: list, columns_names: list, k1: int):\n",
    "    header = pd.MultiIndex.from_product([models_names, columns_names])\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    df['KFold'] = np.arange(1, k1+1)\n",
    "    df.set_index('KFold', inplace=True)\n",
    "    return df\n",
    "\n",
    "def twolevelcv(X: np.array, y: np.array, k1: int, k2: int, models: list, params: dict, rs: int):\n",
    "    \"\"\"Allows to compute two level crossvalidation.\n",
    "\n",
    "    Args:\n",
    "        X (np.array): Features (numeric)\n",
    "        y (np.array): Class (objective variable)\n",
    "        k1 (int): Nº of outer folds\n",
    "        k2 (int): Nº of inner folds\n",
    "        models (list): List of models for comparison\n",
    "        params (dict): Dictionary including the set of parameters. In this case we only tune 1 parameter per model.\n",
    "        rs (int): Random state\n",
    "    Returns:\n",
    "        df: Dataframe\n",
    "    \"\"\"\n",
    "    test_error_dict = {}\n",
    "    k = 0\n",
    "    names = [type(m).__name__ for m in models]\n",
    "    col_names = ['Param. Value', 'Error']\n",
    "    df = dataset_creator(names, col_names, k1)\n",
    "    kf1 = StratifiedKFold(k1, shuffle = True, random_state=rs)\n",
    "    # first level split\n",
    "    for train_idx1, test_idx1 in kf1.split(X, y):\n",
    "        k += 1\n",
    "        kf2 = StratifiedKFold(k2, shuffle = True, random_state=rs)\n",
    "        print(f'Computing KFold {k}/{k1}...')\n",
    "        # second level split\n",
    "        for train_idx2, test_idx2 in tqdm(kf2.split(X[train_idx1, :], y[train_idx1]), total = k2):\n",
    "            X_train = X[train_idx2, :]\n",
    "            y_train = y[train_idx2]\n",
    "            X_test = X[test_idx2, :]\n",
    "            y_test = y[test_idx2]\n",
    "            for name, model in zip(names, models):\n",
    "                if name != 'DummyClassifier':\n",
    "                    pname = list(params[name].keys())[0]\n",
    "                    error_test = []\n",
    "                    for p_ in params[name][pname]:\n",
    "                        pdict = {pname: p_}\n",
    "                        model = model.set_params(**pdict)\n",
    "                        # train the model\n",
    "                        model.fit(X_train, y_train)\n",
    "                        # evaluate performance\n",
    "                        pred2_test = model.predict(X_test)\n",
    "                        error_test.append(np.sum(pred2_test != y_test)/ y_test.shape[0])\n",
    "                    min_param = params[name][pname][np.argmin(error_test)]\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "                    pred2_test = model.predict(X_test)\n",
    "                    error_test = np.sum(pred2_test != y_test)/ y_test.shape[0]\n",
    "                    min_param = np.NaN\n",
    "                df.loc(axis = 1)[name, 'Error'][k] = np.min(error_test)\n",
    "                df.loc(axis = 1)[name, 'Param. Value'][k] = min_param\n",
    "    return df, test_idx1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw, df_Xn_raw = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_methods = ['mean', 'median', 'most_frequent']\n",
    "std_methods = ['standard', 'minmax', 'maxabs', 'robust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = transform_data(df_raw, fill_methods[0], std_methods[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_stdz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Diego\\Documents\\DTU\\Spring2023\\CDA\\CDA_Projects\\Case1\\project.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Diego/Documents/DTU/Spring2023/CDA/CDA_Projects/Case1/project.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m k1 \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Diego/Documents/DTU/Spring2023/CDA/CDA_Projects/Case1/project.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m k2 \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Diego/Documents/DTU/Spring2023/CDA/CDA_Projects/Case1/project.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m Table, test_set_outer \u001b[39m=\u001b[39m twolevelcv(X\u001b[39m=\u001b[39mX_stdz,y\u001b[39m=\u001b[39my_,k1\u001b[39m=\u001b[39mk1,k2\u001b[39m=\u001b[39mk2,model\u001b[39m=\u001b[39mmodels,params\u001b[39m=\u001b[39mparams,r_s\u001b[39m=\u001b[39mrandom_state)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_stdz' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "random_state = 3\n",
    "params = {}\n",
    "lam = np.logspace(-6, 2, 100)\n",
    "C = 1/ lam\n",
    "# C = [200000000, 10000000, 0.1519911082952933, 0.2848035868435805 ]\n",
    "params['LogisticRegression'] = {'C': C}\n",
    "params['DummyRegressor'] = {'strategy': ['mean', 'median', 'quantile']}\n",
    "params['MLPRegressor'] = {'hidden_layer_sizes': [(8, ), (16, ), (20, )]}\n",
    "params['LinearRegression'] = {'fit_intercept': [True, False]}\n",
    "params['Ridge'] = {'alpha': [0.1, 1.0, 10.0]}\n",
    "models = [LogisticRegression(solver='saga', max_iter=1000000, random_state= random_state, tol = 0.003, n_jobs = -1),\n",
    "          DummyRegressor(),\n",
    "          MLPRegressor(solver='adam', activation='logistic', alpha=1e-4, random_state=random_state, max_iter=1000,\n",
    "          early_stopping=True, validation_fraction=0.2, warm_start=True, verbose=False),\n",
    "          LinearRegression(n_jobs=-1),\n",
    "          Ridge(random_state=random_state)]\n",
    "k1 = 10\n",
    "k2 = 10\n",
    "Table, test_set_outer = twolevelcv(df_raw,k1=k1,k2=k2,model=models,params=params,r_s=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.16407864998737"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1.8e04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
