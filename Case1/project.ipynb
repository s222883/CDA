{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twolevelcv(df, k1: int, k2: int, models: list, params: dict, rs: int, fill_methods: list, std_method: list):\n",
    "    \"\"\"Allows to compute two level crossvalidation.\n",
    "\n",
    "    Args:\n",
    "        X (np.array): Features (numeric)\n",
    "        y (np.array): Class (objective variable)\n",
    "        k1 (int): Nº of outer folds\n",
    "        k2 (int): Nº of inner folds\n",
    "        models (list): List of models for comparison\n",
    "        params (dict): Dictionary including the set of parameters. In this case we only tune 1 parameter per model.\n",
    "        rs (int): Random state\n",
    "    Returns:\n",
    "        look at return\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    names = [type(m).__name__ for m in models]\n",
    "    kf1 = KFold(k1, shuffle = True, random_state=rs)\n",
    "    X_raw = df.drop('y', axis=1)\n",
    "    y = df['y']\n",
    "    combs = list(itertools.product(fill_methods,std_method,zip(names,models)))\n",
    "    it_combs = len(combs)\n",
    "    N = X_raw.shape[0]\n",
    "    \n",
    "    best_fill = [0]*k1\n",
    "    best_std = [0]*k1\n",
    "    best_name_model = [0]*k1\n",
    "    errors_out = [0]*k1\n",
    "    \n",
    "    # first level split\n",
    "    for z,(train_idx1, test_idx1) in enumerate(kf1.split(X_raw, y)):\n",
    "        k += 1\n",
    "        kf2 = KFold(k2, shuffle = True, random_state=rs+z+1)\n",
    "        print(f'Computing KFold {k}/{k1}...')\n",
    "        err = [[] for pp in range(it_combs)]\n",
    "        \n",
    "        # second level split\n",
    "        for t,(train_idx2, test_idx2) in tqdm(enumerate(kf2.split(X_raw.iloc[train_idx1, :], y[train_idx1])), total = k2):\n",
    "            for i in range(it_combs):\n",
    "                method = combs[i][0]\n",
    "                std_method = combs[i][1]\n",
    "                name,model = combs[i][2]\n",
    "                X_train,X_test = transform_data(X_raw.iloc[train_idx2, :],X_raw.iloc[test_idx2, :] \\\n",
    "                                                , fill_method=method, std_method=std_method)\n",
    "                y_train = y[train_idx2]\n",
    "                y_test = y[test_idx2]\n",
    "                grid = list(ParameterGrid(params[name]))\n",
    "                n_p = len(grid)\n",
    "                if err[i] == []:\n",
    "                    err[i] = [[] for pp in range(n_p)]\n",
    "                for j in range(n_p):\n",
    "                    p_ = grid[j]\n",
    "                    model = model.set_params(**p_)\n",
    "                    # train the model\n",
    "                    model.fit(X_train, y_train)\n",
    "                    # evaluate performance\n",
    "                    pred2_test = model.predict(X_test)\n",
    "                    error = mse(pred2_test, y_test,squared = False)\n",
    "                    err[i][j].append(error*len(test_idx2)/len(train_idx1))\n",
    "        # inner cv has finished, choose model and param\n",
    "        best_err = np.inf\n",
    "        i_best = None\n",
    "        j_best = None\n",
    "        for i in range(it_combs):\n",
    "            for j in range(len(err[i])):\n",
    "                aux = np.sum(err[i][j])\n",
    "                if aux < best_err:\n",
    "                    i_best = i\n",
    "                    j_best = j\n",
    "                    best_err = aux\n",
    "        method = combs[i_best][0]\n",
    "        std_method = combs[i_best][1]\n",
    "        name,model = combs[i_best][2]\n",
    "        grid = list(ParameterGrid(params[name]))\n",
    "        p_ = grid[j_best]\n",
    "        model = model.set_params(**p_)\n",
    "\n",
    "        X_tr,X_te = transform_data(X_raw.iloc[train_idx1, :], X_raw.iloc[test_idx1, :],  \\\n",
    "                                   fill_method=method, std_method=std_method)\n",
    "        y_te = y[test_idx1]\n",
    "        y_tr = y[train_idx1]\n",
    "        model.fit(X_tr,y_tr)\n",
    "        pred = model.predict(X_te)\n",
    "        error = mse(pred,y_te,squared = False)\n",
    "        \n",
    "        best_fill[z] = method\n",
    "        best_std[z] = std_method\n",
    "        best_name_model[z] = (name,model)\n",
    "        print(f\"fill method: {method}, std_method: {std_method}, model: {name} with parameter: {p_}\")\n",
    "        print(f\"error: {error}\")\n",
    "        errors_out[z] = error*len(test_idx1)/100\n",
    "    \n",
    "    gen_error = np.sum(errors_out)\n",
    "    \n",
    "    return best_fill,best_std,best_name_model,errors_out,gen_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 1/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m k1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     45\u001b[0m k2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 46\u001b[0m best_fill,best_std,best_name_model,errors_out,gen_err \u001b[38;5;241m=\u001b[39m \u001b[43mtwolevelcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_methods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_methods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd_methods\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 54\u001b[0m, in \u001b[0;36mtwolevelcv\u001b[0;34m(df, k1, k2, models, params, rs, fill_methods, std_method)\u001b[0m\n\u001b[1;32m     52\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp_)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# evaluate performance\u001b[39;00m\n\u001b[1;32m     56\u001b[0m pred2_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/CDA/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:1007\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1006\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1007\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1032\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/CDA/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    620\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    621\u001b[0m         coef_,\n\u001b[1;32m    622\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m         positive,\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcd_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    641\u001b[0m     )\n",
      "File \u001b[0;32msklearn/linear_model/_cd_fast.pyx:264\u001b[0m, in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CDA/lib/python3.10/site-packages/numpy/core/getlimits.py:460\u001b[0m, in \u001b[0;36mfinfo.__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, dtype):\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[43mnumeric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;66;03m# In case a float instance was given\u001b[39;00m\n\u001b[1;32m    463\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m numeric\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mtype\u001b[39m(dtype))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df_raw, df_Xn_raw = load_data()\n",
    "std_methods = ['standard','minmax','maxabs','robust'] + list(range(10,81,5))\n",
    "fill_methods = ['mean', 'median']\n",
    "\n",
    "random_state = 3\n",
    "params = {}\n",
    "lam = np.logspace(-2, 3, 100)\n",
    "lam_1 = lam[:]\n",
    "lam_2 = lam[:]\n",
    "l1 = np.linspace(0,1,100)\n",
    "n_est = list(range(20,200,20))\n",
    "m_depth = list(range(3,20,7))\n",
    "lr = np.logspace(-3,0,10)\n",
    "m_sm_spl = list(range(2,81,7))\n",
    "n_neigh = list(range(5,80,5))\n",
    "\n",
    "params['DummyRegressor'] = {'strategy': ['mean', 'median']}\n",
    "params['LinearRegression'] = {'fit_intercept': [True, False]}\n",
    "params['Ridge'] = {'alpha': lam, 'fit_intercept': [True, False],'random_state':[1657]}\n",
    "params['Lasso'] = {'alpha': lam_1, 'fit_intercept': [True, False], 'max_iter': [1000],'random_state':[909123]}\n",
    "params['ElasticNet'] = {'alpha': lam_2, 'l1_ratio': l1, 'fit_intercept': [True,False], \\\n",
    "                                                            'max_iter':[1000], 'random_state':[123]}\n",
    "params['RandomForestRegressor'] = {'n_estimators':n_est, 'max_depth':m_depth, \\\n",
    "                                                'min_samples_split':m_sm_spl[:], 'random_state':[456]}\n",
    "params['GradientBoostingRegressor'] = {'n_estimators': n_est, 'learning_rate':lr, \\\n",
    "                                        'max_depth':m_depth, 'min_samples_split':m_sm_spl, 'random_state':[789]}\n",
    "params['KNeighborsRegressor'] = {'n_neighbors':n_neigh,'n_jobs': [-1],\\\n",
    "                                                           'weights':['uniform', 'distance'],'p':[1,2]}\n",
    "\n",
    "# Create a list of models\n",
    "models = [Ridge(),\n",
    "          KNeighborsRegressor(), \n",
    "          LinearRegression(),\n",
    "          Lasso(),\n",
    "          ElasticNet(),\n",
    "          RandomForestRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          DummyRegressor()]\n",
    "k1 = 10\n",
    "k2 = 10\n",
    "best_fill,best_std,best_name_model,errors_out,gen_err = twolevelcv(df_raw, k1=k1, k2=k2, models=models,\\\n",
    "                        params=params, rs=random_state, fill_methods=fill_methods, std_method = std_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.742535519630007"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
